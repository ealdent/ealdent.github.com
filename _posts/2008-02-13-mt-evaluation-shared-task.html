---
layout: post
title: "MT Evaluation Shared Task"
tags: ["acl", "acl", "computational linguistics", "computational linguistics", "machine translation", "machine translation", "machine translation evaluation", "machine translation evaluation", "mt eval", "mt eval", "workshops", "workshops"]
---
<hr /><br />Original post can be found at:  <a href="http://ealdent.wordpress.com/2008/02/13/mt-evaluation-shared-task/" target="_blank">http://ealdent.wordpress.com/2008/02/13/mt-evaluation-shared-task/</a><br /><br />
<p align="justify">At <a href="http://www.ling.ohio-state.edu/acl08/index.html" target="_blank">ACL this year</a>, the <a href="http://www.statmt.org/wmt08/index.html" target="_blank">Third Workshop on Stastical Machine Translation</a> will be held and they are featuring <a href="http://www.statmt.org/wmt08/shared-evaluation-task.html" target="_blank">a shared task on MT evaluation</a>.  The shared task will involve evaluating output from the shared translation task, which will be released on March 24th, with short papers and rankings due on April 4th.  I created an <a href="http://www.cs.cmu.edu/~jmadams/MTFinalProject.pdf" target="_blank">MT evaluation system</a> (pdf) last year for a class (on MT, no less), though I doubt it would do particularly well.  I outperformed BLEU, but fell short of METEOR.  In any case, it might be interesting to play with the data and certainly will be interesting to read the papers.  My system does perform sentence-level ranking as one of its primary goals, which is also a goal stated by the shared task.</p>
