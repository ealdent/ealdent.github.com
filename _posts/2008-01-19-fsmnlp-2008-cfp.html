---
layout: post
title: "FSMNLP 2008 CFP"
tags: ["call for papers", "call for papers", "cfp", "cfp", "computational linguistics", "computational linguistics", "computational morphology", "computational morphology", "finite state methods", "finite state methods", "fsmnlp", "fsmnlp", "italy", "italy", "natural language processing", "natural language processing"]
---
Original post can be found at:  http://ealdent.wordpress.com/2008/01/19/fsmnlp-2008-cfp/<br /><br />
<p align="justify">FSMNLP 2008 (Finite State Methods and Natural Language Processing) has issued their first Call for Papers (CFP).  The deadline is May 11, 2008 and the conference will take place on September 11-12, 2008.  Not the best time to be travelling perhaps, but this year it will be in Ispra, Lago Maggiore, Italy!  That's in the far north of Italy, right next to the Swiss border.  From the pictures I'm finding on Google, it's a gorgeous resort area.</p>

<div><img src="http://ealdent.files.wordpress.com/2008/01/lagomaggiore.jpg" alt="Lago Maggiore - site of FSMNLP 2008" /></div>
<p align="justify">The sorts of things they are interested in include:</p>

<ul>
	<li>NLP applications and linguistic aspects of finite state methods</li>
	<li>Finite state models of language</li>
	<li>Practices for building lexical transducers for the world's languages</li>
	<li>Specification and implementation of sets, relations, and multiplicities in NLP using finite state devices</li>
	<li>Machine learning of finite state models of natural language</li>
	<li>Finite state manipulation software</li>
</ul>
The special theme this year will be on high performance finite state systems in large scale NLP applications.
<p align="justify">I am going to try really hard to get something together for it this year.  I had a project last year that was potentially worth submitting, but I wasn't able to get it done in time.  Unfortunately, it has languished since then as other, more pressing matters have superceded it.  Going to Northern Italy ought to be motivation enough, though, don't you think?</p>
The entire CFP is below the jump and is also available on <a href="http://langtech.jrc.it/FSMNLP2008/m/CFP.html" target="_blank">their website</a>:

<!--more-->
<h2><font size="+1">Call for papers</font></h2>
<a href="http://langtech.jrc.it/FSMNLP2008"><b><font color="blue">Finite-State Methods and Natural Language Processing - FSMNLP 2008</font></b></a>
Seventh International Workshop
Joint Research Centre of the EC, Ispra, Italy
11-12 September 2008

This year <b>FSMNLP</b> is merged with the <a href="http://www.fastar.org/"><b><font color="blue">FASTAR (Finite Automata Systems - Theoretical and Applied Research)</font></b></a> workshop.
<h3>AIM and MOTIVATION</h3>
The aim of the <b>FSMNLP 2008</b> is to bring together members of the research and industrial community working on finite-state based models in language technology, computational linguistics, web mining, linguistics, and cognitive science or on related  theory and methods in fields such as computer science and mathematics. The workshop will be a forum for researchers and practicioners working
<ul>
	<li>on NLP applications,</li>
	<li>on the theoretical and implementation aspects, or</li>
	<li>on their combination.</li>
</ul>
<h3>SPECIAL THEME</h3>
The special theme of <b>FSMNLP 2008</b> centers around high performance finite-state devices in large-scale natural language text processing systems and applications. We invite in particular novel high-quality papers related  to the topics including:
<ul>
	<li>practices and experience in deployment of finite-state techniques in real-world applications processing massive amount of natural language data</li>
	<li>industrial-strength finite-state pattern engines for information retrieval, information extraction and related text-mining tasks</li>
	<li>scalability issues in FS-based large-scale text processing systems</li>
	<li>efficient finite-state methods in search engines</li>
	<li>implementation, construction, compression and processing techniques for huge finite-state devices and networks</li>
	<li>novel application and efficiency-oriented finite-state paradigms (compilation and processing), e.g., finite-state devices with rich label annotatations, unification-based finite-state devices</li>
	<li>comparative studies of time and space efficient finite-state methods (vs. other techniques) utilized in NLP applications</li>
	<li>novel appllication areas for finite-state devices in text processing and information management systems</li>
	<li>design patterns for implementing finite-state devices and toolkits</li>
</ul>
<h3>OTHER TOPICS</h3>
We also invite submissions that are related to the traditional <b>FSMNLP</b> themes including but not limited to:
<h3>1. NLP applications and linguistic aspects of finite-state methods</h3>
The topic includes but is not restricted to:
<ul>
	<li>speech, sign language, phonology, hyphenation, prosody,</li>
	<li>scripts, text normalization, segmentation, tokenization, indexing,</li>
	<li>morphology, stemming, lemmatisation, information retrieval, web mining, spelling correction,</li>
	<li>syntax, POS tagging, partial parsing, disambiguation, information extraction, question answering</li>
	<li>machine translation, translation memories, glossing, dialect adaptation,</li>
	<li>annotated corpora and treebanks, semi-automatic annotation, error mining, searching</li>
</ul>
<h3>2. Finite-state models of language</h3>
With this more focused topic (inside 1) we invite papers on aspects that motivate sufficiency of finite-state methods or their subsets for capturing various requirements of natural language processing. The topic includes but is not restricted to:
<ul>
	<li>performance, linguistic applicability, finite-state hypotheses</li>
	<li>Zipf's law and coverage, model checking against finite corpora</li>
	<li>regular approximations under parameterized complexity, limitations and definitions of      relevant complexities such as ambiguity, recursion, crossings, rule applications,      constraint violations, reduplication, exponents, discontinuity, path-width, and induction depth</li>
	<li>similarity inferences, dissimilation, segmental length, counter-freeness, asynchronous machines</li>
	<li>garden-path sentences, deterministic parsing, expected parses, Markov chains</li>
	<li>incremental parsing, uncertainty, reliability/variance in stochastic parsing, linear sequential machines</li>
</ul>
<h3>3. Practices for building lexical transducers for the world's languages.</h3>
The topic accounts for usability of finite-state methods in NLP. It includes but is not restricted to:
<ul>
	<li>required user training and consultation, learning curve of non-specialists</li>
	<li>questionnaires, discovery methods, adaptive computer-aided glossing and interlinearization</li>
	<li>example-based grammars, unsupervised learning, semi-automatic learning, user-driven learning (see topic 5 too)</li>
	<li>low literacy level and restricted availability of training data, writing systems/phonology under development,      new non-Roman scripts, endangered languages</li>
	<li>linguist's workbenches, stealth-to-wealth parser development</li>
	<li>experiences of using existing tools (e.g. TWOL) for computational morphology and phonology</li>
</ul>
<h3>4. Specification and implementation of sets, relations and multiplicities in NLP using finite state devices</h3>
The topic includes but is not restricted to:
<ul>
	<li>regular rule formalisms, grammar systems, expressions, operations, closure properties, complexities</li>
	<li>algorithms for compilation, approximation, manipulation, optimization, and lazy evaluation of finite machines</li>
	<li>finite string and tree automata, transducers, morphisms and bimorphisms</li>
	<li>weights, registers, multiple tapes, alphabets, state covers and partitions, representations</li>
	<li>locality, constraint propagation, star-free languages, data vs. query complexity</li>
	<li>logical specification, MSO(SLR,matches), FO(Str,&lt;), LTL, generalized restriction, local grammars</li>
	<li>multi-tape automata, same-length relations and partition-based morphology, Semitic morphology</li>
	<li>autosegmental phonology, shuffle, trajectories, synchronization, segmental anchoring, alignment constraints,      syllable structure, partial-order reductions</li>
	<li>varieties of regular languages and relations, descriptive complexity of finite-state based grammars</li>
	<li>automaton-based approaches to declarative constraint grammars, constraints in optimality theory</li>
	<li>parallel corpus annotations, register automata, acyclic timed automata</li>
</ul>
<h3>5. Machine learning of finite-state models of natural language</h3>
This topic includes but is not restricted to:
<ul>
	<li>learning regular rule systems, learning topologies of finite automata and transducers</li>
	<li>parameter estimation and smoothing, lexical openness</li>
	<li>computer-driven grammar writing, user-driven grammar learning, discovery procedures</li>
	<li>data scarcity, realistic variations of Gold's model, learnability and cognitive science</li>
	<li>incompletely specified finite-state networks</li>
	<li>model-theoretic grammars, gradient well/ill-formedness</li>
</ul>
<h3>6. Finite-state manipulation software (with relevance to the above themes)</h3>
This topic includes but is not restricted to
<ul>
	<li>regular expression pre-compilers such as regexopt, xfst2fsa, standards and interfaces for finite-state based      software components, conversion tools</li>
	<li>tools such as LEXC, Lextools, Intex, XFST, FSM, GRM, WFSC, FIRE Engine, FADD, FSA/UTR, SRILM, FIRE Station and Grail</li>
	<li>free or almost free software such as MIT FST, Carmel, RWTH FSA, FSA Utilities, FSM2.0, Unitex, OpenFIRE,      OpenFST, Vaucanson, SFST, PCKIMMO, MONA, Hopskip, ASTL, UCFSM, HaLeX, SML, and WFST     (see <a href="http://forums.csc.fi/kitwiki/pilot/view/KitWiki/FsmReg"><font color="blue">FSM Registry</font></a> for more examples)</li>
	<li>results obtainable with such exploration tools as automata, Autographe, Amore, and TESTAS</li>
	<li>visualization tools such as Graphviz and Vaucanson-G</li>
	<li>language-specific resources and descriptions, freely available benchmarking resources</li>
</ul>
The descriptions of the topics above are not meant to be complete, and should extend to cover all traditional FSMNLP topics. Submitted papers or abstracts may fall in several categories.
<h3>SUBMISSION</h3>
We expect three kinds of submissions:
<ul>
	<li> full papers,</li>
	<li> short papers, and</li>
	<li> interactive software demos.</li>
</ul>
Submissions are electronic and in PDF format via a web-based submission server.  Authors are encouraged to use Springer <a href="http://www.springer.com/east/home/computer/lncs?SGWID=5-164-7-72376-0"> <font color="blue">LNCS style (Proceedings and Other Multiauthor Volumes)</font></a> for LaTeX in producing the PDF document.  The page limit for full papers is 12 pages, whereas short papers and  software demo descriptions are limited to 6 pages. The information about the author(s)  should be omitted in the submitted papers since the review process wil be blind.
<h3>PUBLICATION</h3>
The papers and abstracts will be published in FSMNLP 2008 proceedings.  Publication of revised versions of the papers in a special journal issue  is planned.
<h3>IMPORTANT DATES</h3>
<ul>
	<li>Paper submissions due:  11 May</li>
	<li>Notification of acceptance:  11 June</li>
	<li>Camera-ready versions due: 30 June</li>
</ul>
