---
layout: post
title: "Goodbye Systran"
tags: ["computational linguistics", "computational linguistics", "google", "google", "language modeling", "language modeling", "machine translation", "machine translation", "mt", "mt", "natural language processing", "natural language processing", "nlp", "nlp", "statistical machine translation", "statistical machine translation", "systran", "systran", "translation", "translation"]
---
Original post can be found at:  <a href="http://ealdent.wordpress.com/2007/10/22/goodbye-systran/" target="_blank">http://ealdent.wordpress.com/2007/10/22/goodbye-systran/</a><br /><br />
Google <a href="http://googleresearch.blogspot.com/2006/04/statistical-machine-translation-live.html" target="_blank">announced </a>that it has abandoned Systran as its translation system for the 22 languages it services besides Arabic, Chinese and Russian.  Systran is one of the oldest machine translation companies around.  When Microsoft launched its service recently, it announced that it would be supplementing its translations with Systran.  Systran uses rule-based systems that have been massively tweaked to produce results that most would agree are still pretty crappy.  They get some basic stuff right, but once you start venturing off into uncommon word usages and complex constructions, all bets are off.  Some translation sites use Systran and others like freetranslation.com use their own system.  Babel Fish is perhaps the most well-known site still using Systran.

So Google is switching over to its own statistical machine translation system for all 25 language pairs.  Statistical machine translation systems typically look at two different kinds of text:  aligned text in two languages (bitext) and monolingual text.  The monolingual text is used to build a statistical model of the language so that output will conform to the target language rather than the original.  For example, in German, the auxiliary verb comes in second position as in English, but the main verb often comes in final position.  Reordering properly isn't easy and this model helps make the output more natural.  Bitexts are texts that have been translated from language to another and then aligned word-by-word.  The actual alignment may be done by hand at the sentence level but the vast amount of human effort involved means that at the word level it is usually done automatically.  Getting good alignments is an ongoing area of research that is quite far from perfect.

The thing that Google has going for it is that with statistical machine translation, the more data the better.  And Google is overflowing with it.  It'll be interesting to see how their systems progress.
